{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'floor_reached': '20',\n",
       " 'character_chosen': None,\n",
       " 'victory': True,\n",
       " 'killed_by': None,\n",
       " 'master_deck': None,\n",
       " 'relics': None,\n",
       " 'boss_relics': None,\n",
       " 'score': None,\n",
       " 'playtime': None,\n",
       " 'neow_bonus': None,\n",
       " 'neow_cost': None,\n",
       " 'campfire_rested': None,\n",
       " 'campfire_upgraded': None}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import codecs\n",
    "import chardet\n",
    "import json\n",
    "\n",
    "columns = ['floor_reached','character_chosen','victory','killed_by','master_deck','relics','boss_relics','score','playtime','neow_bonus','neow_cost','campfire_rested','campfire_upgraded']\n",
    "\n",
    "test_dict = {'floor_reached': '20', 'victory': True, 'pimple': 'chin'}\n",
    "\n",
    "def schema_sort(in_dict):\n",
    "    columns = ['floor_reached','character_chosen','victory','killed_by','master_deck','relics','boss_relics','score','playtime','neow_bonus','neow_cost','campfire_rested','campfire_upgraded']\n",
    "    run_dict = {}\n",
    "    for i in columns:\n",
    "        if i in in_dict.keys():\n",
    "            temp = {i: in_dict[i]}\n",
    "            run_dict.update(temp)\n",
    "        else:\n",
    "            run_dict.update({i:None})\n",
    "    return run_dict\n",
    "\n",
    "\n",
    "schema_sort(test_dict)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import DictWriter\n",
    "\n",
    "def run_todict(input_file):\n",
    "    with open(input_file, 'r') as input_file:\n",
    "        run_list = input_file.readlines()\n",
    "        for i in run_list:\n",
    "            input_dict = json.loads(i)\n",
    "            run_dict = schema_sort(input_dict)\n",
    "        return run_dict\n",
    "\n",
    "    \n",
    "def append_dict_as_row(input_dir):\n",
    "    count = 1\n",
    "    for file in os.listdir(input_dir):\n",
    "        with open(f\"run.csv\", 'a+', newline='') as write_obj:\n",
    "            run_dict = run_todict(f\"{input_dir}{file}\")\n",
    "            dict_writer = DictWriter(write_obj, fieldnames=run_dict.keys())\n",
    "            if count == 1:\n",
    "                dict_writer.writeheader()\n",
    "            dict_writer.writerow(run_dict)\n",
    "            count += 1\n",
    "append_dict_as_row(\"runs/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "def tobig_query():\n",
    "    \"\"\"\n",
    "    Writes our pandas dataframe to BigQuery\n",
    "    \"\"\"\n",
    "    #hardcoded column names\n",
    "    cols = ['floor_reached','character_chosen','victory','killed_by','master_deck','relics','boss_relics','score','playtime','neow_bonus','neow_cost','campfire_rested','campfire_upgraded']\n",
    "    #use run.csv\n",
    "    completed_run_df = pd.read_csv('run.csv', names=cols)\n",
    "    completed_run_df['deck_size'] = completed_run_df['master_deck'].map(lambda x: len(ast.literal_eval(x)))\n",
    "    #set client object with project id\n",
    "    client = bigquery.Client(project= 'deb-01-346001')\n",
    "    #set project dataset and destination table name\n",
    "    table = 'STS_run_data.april_runs'\n",
    "    #enter partial schema \n",
    "    job_config = bigquery.LoadJobConfig(schema = [\n",
    "        bigquery.SchemaField(\"floor_reached\", bigquery.enums.SqlTypeNames.INTEGER),\n",
    "        bigquery.SchemaField(\"playtime\", bigquery.enums.SqlTypeNames.INTEGER)])\n",
    "    #load df into table\n",
    "    job = client.load_table_from_dataframe(completed_run_df, table, job_config=job_config)\n",
    "\n",
    "tobig_query()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
