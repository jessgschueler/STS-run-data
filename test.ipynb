{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import codecs\n",
    "import chardet\n",
    "import json\n",
    "\n",
    "def run_txt(input_dir, character):\n",
    "    \"\"\"\n",
    "    Renames game generated .run files into .txt files\n",
    "\n",
    "    Args:\n",
    "        input_dir (dir): dir with .run files\n",
    "        character (str): character name\n",
    "    \"\"\"\n",
    "    run = 1\n",
    "    for file in os.listdir(input_dir):\n",
    "        os.rename(f'{input_dir}{file}', f'{input_dir}{character}{run}.txt')\n",
    "        run += 1\n",
    "\n",
    "\n",
    "def run_tojson(input_dir, output_file):\n",
    "    \"\"\"\n",
    "    Input all run.txt files into json file\n",
    "\n",
    "    Args:\n",
    "        input_dir (dir): dir with run.txt files\n",
    "        output_file (file): empty json file\n",
    "    \"\"\"\n",
    "    for file in os.listdir(input_dir):\n",
    "        with open(f'{input_dir}{file}', 'r') as input_file:\n",
    "            run_dict = input_file.readlines()\n",
    "            with open(output_file, 'a') as output_json:\n",
    "                json.dump(run_dict, output_json)\n",
    "\n",
    "run_tojson('./watcher/', './watcher_runs.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'ironclad18.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/5x/ph8t_tlx7kb2_w43x1mfvwd80000gn/T/ipykernel_7775/2889186043.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0mcleantxt_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileContent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mseed_del\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./ironclad/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/5x/ph8t_tlx7kb2_w43x1mfvwd80000gn/T/ipykernel_7775/2889186043.py\u001b[0m in \u001b[0;36mseed_del\u001b[0;34m(input_dir)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \"\"\"\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcleantxt_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcleantxt_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0mfileContent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m',\"special_seed\":0,'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ironclad18.txt'"
     ]
    }
   ],
   "source": [
    "def seed_del(input_dir):\n",
    "    \"\"\"\n",
    "    Finds unecessary data and deletes\n",
    "\n",
    "    Args:\n",
    "        input_dir (dir): dir with .run files\n",
    "    \"\"\"\n",
    "    for file in os.listdir(input_dir):\n",
    "        with open(file, 'r+') as cleantxt_file:\n",
    "            for line in cleantxt_file:\n",
    "                fileContent = re.sub(',\"special_seed\":0,', ',', line)\n",
    "                cleantxt_file.write(fileContent)\n",
    "\n",
    "seed_del('./ironclad/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_totsv(input_dir, output_file):\n",
    "    \"\"\"\n",
    "    Converts run.txt files into TSV files\n",
    "\n",
    "    Args:\n",
    "        input_dir (dir): dir with run.txt files\n",
    "        output_file (file): tsv file\n",
    "    \"\"\"\n",
    "    for file in os.listdir(input_dir):\n",
    "        with open(f'{input_dir}{file}', 'r') as input_file:\n",
    "            run_list = input_file.readlines()\n",
    "            for i in run_list:\n",
    "                run_dict = json.loads(i)\n",
    "                tsv_columns = run_dict.keys()\n",
    "                tsv_data = '  '.join(tsv_columns) + '\\n'\n",
    "                new_row = list()\n",
    "                for col in tsv_columns:\n",
    "                    new_row.append(str(run_dict[col]))\n",
    "                tsv_data += '  '.join(new_row) + '\\n'\n",
    "                with open(output_file, 'a') as out_tsv:\n",
    "                    out_tsv.write(tsv_data)\n",
    "\n",
    "\n",
    "run_totsv('./silent/', './silent_runs.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def to_csv(input_tsv, output_csv): \n",
    "    \"\"\"\n",
    "    Converts TSV file to CSV file\n",
    "\n",
    "    Args:\n",
    "        input_tsv (file): tsv file\n",
    "        output_csv (file): csv file\n",
    "    \"\"\"\n",
    "    with open(input_tsv, 'r') as tsv_file:  \n",
    "        with open(output_csv, 'w') as csv_file:\n",
    "            for line in tsv_file:\n",
    "                fileContent = re.sub(\"  \", \",\", line)\n",
    "                csv_file.write(fileContent)\n",
    "\n",
    "to_csv('silent_runs.tsv', 'silent.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "from google.cloud import bigquery\n",
    "import pandas\n",
    "import pytz\n",
    "\n",
    "# def add_dataframes():\n",
    "\n",
    "cols = ['gold_per_floor','floor_reached','playtime','items_purged','score','play_id','local_time','is_ascension_mode','campfire_choices','neow_cost','seed_source_timestamp','circlet_count','master_deck','relics','potions_floor_usage','damage_taken','seed_played','potions_obtained','is_trial','path_per_floor','character_chosen','items_purchased','campfire_rested','item_purchase_floors','current_hp_per_floor','gold','neow_bonus','is_prod','is_daily','chose_seed','campfire_upgraded','win_rate','timestamp','path_taken','build_version','purchased_purges','victory','max_hp_per_floor','card_choices','player_experience','relics_obtained','event_choices','is_beta','boss_relics','items_purged_floors','is_endless','potions_floor_spawned','killed_by','ascension_level','extra']\n",
    "defect_df = pd.read_csv('CSVData/defect.csv', names=cols)\n",
    "watcher_df = pd.read_csv('CSVData/watcher.csv', names=cols)\n",
    "silent_df = pd.read_csv('CSVData/silent.csv', names=cols)\n",
    "ironclad_df = pd.read_csv('CSVData/ironclad.csv', names=cols)\n",
    "\n",
    "all_chars_df_mess = pd.concat([defect_df,watcher_df,silent_df,ironclad_df])\n",
    "\n",
    "all_chars_df = all_chars_df_mess.drop_duplicates()\n",
    "\n",
    "completed_run_df = all_chars_df[all_chars_df.floor_reached != 0]\n",
    "\n",
    "completed_run_df\n",
    "\n",
    "client = bigquery.Client(project= 'deb-01-346001')\n",
    "table = 'STS_run_data.april_runs'\n",
    "job_config = bigquery.LoadJobConfig()\n",
    "job = client.load_table_from_dataframe(completed_run_df, table, job_config=job_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
